{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt3jOVZIjuydtv4IIWQAV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MehniLozo/GANAVATAR/blob/master/GANAVATAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skj5NPRRGAz8"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "  from google.colab import drive\n",
        "  #drive.amount('/content/drive', force_remount=True)\n",
        "  print(\"Google Drive mounted successfully!\")\n",
        "  %tensorflow_version 2.x\n",
        "except Exception as e:\n",
        "  print(\"Error while mounting Google Drive: {}\".format(str(e)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os,time\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Reshape,Dropout,Dense\n",
        "from tensorflow.keras.layers import Flatten,BatchNormalization\n",
        "from tensorflow.keras.layers import Activation,ZeroPadding2D\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Sequential, Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n"
      ],
      "metadata": {
        "id": "U5PrsLYiGTpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HjY57zsXIu_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "metadata": {
        "id": "TNtGyjASKmfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_CHANNELS = 3\n",
        "GENERATE_RESOLUTION_FACTOR = 3\n",
        "GENERATE_SQUARE = 32 * GENERATE_RESOLUTION_FACTOR\n",
        "\n",
        "PREVIEW_ROWS, PREVIEW_COLS = 4,7\n",
        "PREVIEW_MARGIN = 16\n",
        "\n",
        "# source vector size to generate images\n",
        "SEED_SIZE = 100\n",
        "\n",
        "# Model config\n",
        "DATA_PATH = ''\n",
        "FOLDER_NAME = 'cartoonset30k'\n",
        "\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 61000\n",
        "\n",
        "print(f\"Image details: {GENERATE_SQUARE}px\")\n"
      ],
      "metadata": {
        "id": "qxMuGo5eKtPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_binary_path = os.path.join(DATA_PATH,\n",
        "    f'training_data_{FOLDER_NAME}_{GENERATE_SQUARE}_{GENERATE_SQUARE}.npy')\n",
        "print(\"Binary file name: \", training_binary_path)\n",
        "\n",
        "\n",
        "if not os.path.isfile(training_binary_path):\n",
        "  start = time.time()\n",
        "  print(\"File not found, loading training images...\")\n",
        "\n",
        "  training_data = []\n",
        "  faces_path = os.path.join(DATA_PATH, FOLDER_NAME)\n",
        "  faces_path_filenames = os.listdir(faces_path)\n",
        "\n",
        "  for filename in tqdm(faces_path_filenames):\n",
        "      path = os.path.join(faces_path,filename)\n",
        "      # Convert RGBA to RGB format\n",
        "      try:\n",
        "        image = Image.open(path).convert(\"RGB\").resize((GENERATE_SQUARE,GENERATE_SQUARE),Image.ANTIALIAS)\n",
        "        training_data.append(np.asarray(image))\n",
        "      except Exception as e:\n",
        "        pass\n",
        "\n",
        "  training_data = np.reshape(training_data,(-1,GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS))\n",
        "  training_data = training_data.astype(np.float32)\n",
        "  training_data = training_data / 127.5 - 1\n",
        "\n",
        "  print(\"Training images -> binary form file\")\n",
        "  np.save(training_binary_path,training_data)\n",
        "  stop = time.time()-start\n",
        "  print (f'Image preprocess time: {hms_string(stop)}')\n",
        "else:\n",
        "  print(\"Loading previous training binary file ...\")\n",
        "  load_data_start_time = time.time()\n",
        "  training_data = np.load(training_binary_path)\n",
        "  load_data_tat = time.time() - load_data_start_time\n",
        "  print(\"Data load time: \", hms_string(load_data_tat))\n",
        ""
      ],
      "metadata": {
        "id": "3QP4nfi_NV5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffling the dataset and creating batches\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(training_data)\n",
        "print(\"Length of total images\", len(training_data))\n",
        "print(\"Length of total batches\",len(train_dataset))\n",
        "print(\"Length of images in one batch: \", len(list(train_dataset.as_numpy_iterator())[0]))"
      ],
      "metadata": {
        "id": "MdEx8aDgV0tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0Rl9poOeOjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definition of the models (USAGE KERAS SEQUENTIAL API)\n",
        "# GENERATOR SIDE\n",
        "def build_generator(seed_size,channels):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(4*4*256,activation = 'relu',input_dim = seed_size))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "  model.add(Reshape((4,4,256)))\n",
        "\n",
        "  model.add(Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 8, 8, 256)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "\n",
        "  model.add(Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "  assert model.output_shape == (None, 16, 16, 256)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "\n",
        "  model.add(Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 32, 32, 256)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "\n",
        "  model.add(Conv2DTranspose(64, (5, 5), strides=(3, 3), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 96, 96, 64)\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU())\n",
        "\n",
        "  model.add(Conv2DTranspose(3, (5, 5), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
        "  assert model.output_shape == (None, 96, 96, 3)\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "gu8zmYw9WZSs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discriminator\n",
        "# CNN image classifier\n",
        "def build_discriminator(image_shape):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape,\n",
        "                     padding=\"same\"))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
        "  model.add(BatchNormalization(momentum=0.7))\n",
        "  model.add(LeakyReLU(alpha=0.3))\n",
        "\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.7))\n",
        "  model.add(LeakyReLU(alpha=0.3))\n",
        "\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
        "  model.add(BatchNormalization(momentum=0.8))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "Oi8eK73CelHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a0386cOAelQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}